<div align="center">
<h1>Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning</h1>

<a href="https://arxiv.org/abs/2503.11651"><img src="https://img.shields.io/badge/arXiv-2503.11651-b31b1b" alt="arXiv"></a>
<a href="https://vgg-t.github.io/"><img src="https://img.shields.io/badge/Project_Page-4CAF50" alt="Project Page"></a>
<a href='https://huggingface.co/spaces/facebook/vggt'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-blue'></a>
<a href="https://github.com/Jacky1128/RepMTL/stargazers"><img src="https://img.shields.io/github/stars/Jacky1128/RepMTL?style=social" alt="Stars"></a>


**[The Hong Kong University of Science and Technology](https://hkust.edu.hk)**; **[Westlake University](https://en.westlake.edu.cn)**


[Zedong Wang](https://jacky1128.github.io), [Siyuan Li](https://lupin1998.github.io), [Dan Xu](https://www.danxurgb.net)
</div>

```bibtex
@inproceedings{iccv2025repmtl,
  title={Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning},
  author={Wang, Zedong and Li, Siyuan and Xu, Dan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2025}
}
```

## Overview

Rep-MTL (ICCV 2025) is a representation-level regularization method for multi-task learning that introduces task saliency-based objectives to encourage cross-task feature sharing and mitigate negative transfer.



## Updates
- [June 26, 2025] ðŸŽ‰ Our paper has been accepted to ICCV 2025! We are currently working on cleaning and re-organizing our codebase. Stay tuned for updates! Please feel free to open an issue for discussions.

## Acknowledgements

Thanks to these public repositories: [LibMTL](https://github.com/facebookresearch/PoseDiffusion), [CAGrad](https://github.com/Cranial-XIX/CAGrad), [FAMO](https://github.com/Cranial-XIX/FAMO) and many other inspiring works in the community.
