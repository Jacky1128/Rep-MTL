<div align="center">
<h1>Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning</h1>

<a target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Paper-RepMTL" alt="Paper PDF">
</a>
<a href="https://arxiv.org/abs/2503.11651"><img src="https://img.shields.io/badge/arXiv-2503.11651-b31b1b" alt="arXiv"></a>
<a href="https://vgg-t.github.io/"><img src="https://img.shields.io/badge/Project_Page-green" alt="Project Page"></a>
<a href='https://huggingface.co/spaces/facebook/vggt'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-blue'></a>


**[The Hong Kong University of Science and Technology](https://www.robots.ox.ac.uk/~vgg/)**; **[Westlake University](https://ai.facebook.com/research/)**


[Zedong Wang](https://jytime.github.io/), [Siyuan Li](https://silent-chen.github.io/), [Dan Xu](https://nikitakaraevv.github.io/)
</div>

```bibtex
@inproceedings{iccv2025repmtl,
  title={Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning},
  author={Wang, Zedong and Li, Siyuan and Xu, Dan},
  booktitle={Proceedings of the IEEE/CVF Internatial Conference on Computer Vision},
  year={2025}
}
```

## Acknowledgements

Thanks to these great repositories: [LibMTL](https://github.com/facebookresearch/PoseDiffusion), [VGGSfM](https://github.com/facebookresearch/vggsfm), [CoTracker](https://github.com/facebookresearch/co-tracker) and many other inspiring works in the multi-task learning community.